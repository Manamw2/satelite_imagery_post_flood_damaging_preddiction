{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":318,"status":"ok","timestamp":1684570238723,"user":{"displayName":"Bishoy Tadros","userId":"03823867321940186287"},"user_tz":-180},"id":"dd-Ful2MgHqt"},"outputs":[],"source":["import cv2\n","import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import sklearn.metrics\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, f1_score\n","from sklearn.model_selection import GridSearchCV\n","from xgboost import XGBClassifier\n","from skimage.feature import hog, local_binary_pattern\n","from typing import List, Tuple"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"U6acLiz9gHq0"},"source":["<font size=20>Pre-Processing</font>"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":412,"status":"ok","timestamp":1684570249625,"user":{"displayName":"Bishoy Tadros","userId":"03823867321940186287"},"user_tz":-180},"id":"1SZteCgqgHq2"},"outputs":[],"source":["def process_images(folder_path: str) -> List:\n","    \"\"\"\n","    Process images from the given folder path and return a list of processed images.\n","    :param folder_path: folder path\n","    :return: list of processed images\n","    \"\"\"\n","    # get all the images from the folder\n","    images = [cv2.imread(folder_path + '/' + image)\n","              for image in os.listdir(folder_path)]\n","    # resize the images\n","    images = [cv2.resize(image, (224, 224)) for image in images]\n","    # convert the images to grayscale\n","    images = [cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) for image in images]\n","    return images\n","\n","\n","def extract_HOG_features(images: List) -> List:\n","    \"\"\"\n","    Extract features from the given images and return a list of features.\n","    :param images: list of images\n","    :return: list of features\n","    \"\"\"\n","    # create a list to store the features\n","    features = []\n","    # loop through the images\n","    for image in images:\n","        # extract the features\n","        hog_features = hog(image, orientations=8, pixels_per_cell=(\n","            16, 16), cells_per_block=(1, 1))  # Extract HOG features\n","        # append the features to the features list\n","        features.append(hog_features)\n","    return features\n","\n","def extract_LBP_features(images):\n","  # Extract LBP features\n","  radius = 1  # LBP radius\n","  n_points = 8 * radius  # Number of LBP sampling points\n","  hists = []\n","  for image in images:\n","    lbp = local_binary_pattern(image, n_points, radius, method='uniform')\n","    # Calculate histogram of LBP features\n","    hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, n_points + 3), range=(0, n_points + 2))\n","    hist = hist.astype(\"float\")\n","    hist /= (hist.sum() + 1e-7)  # Normalize the histogram\n","    hists.append(hist)\n","  return hists\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# Load images and corresponding labels\n","def load_images_and_labels():\n","    images = []\n","    labels = []\n","    for i in range(365):\n","        img = cv2.imread(f'/content/drive/MyDrive/Satellite_Imagery/dataset/train/flooded/{i}.jpg', cv2.IMREAD_GRAYSCALE)\n","        img = cv2.resize(img, (512, 512))\n","        images.append(img)\n","        labels.append(0)\n","    for i in range(578, 943):\n","        img = cv2.imread(f'/content/drive/MyDrive/Satellite_Imagery/dataset/train/non-flooded/{i}.jpg', cv2.IMREAD_GRAYSCALE)\n","        img = cv2.resize(img, (512, 512))\n","        images.append(img)\n","        labels.append(1)\n","    return images, labels\n","\n","# Extract SIFT features from images\n","def extract_SIFT_features(images, max_descriptors=100):\n","    sift = cv2.SIFT_create()\n","    keypoints_list = []\n","    descriptors_list = []\n","    for image in images:\n","        keypoints, descriptors = sift.detectAndCompute(image, None)\n","        if len(keypoints) > max_descriptors:\n","            keypoints = keypoints[:max_descriptors]\n","            descriptors = descriptors[:max_descriptors]\n","        keypoints_list.append(keypoints)\n","        descriptors_list.append(descriptors)\n","    return keypoints_list, descriptors_list\n","\n","\n","# Flatten descriptors and prepare feature matrix\n","def prepare_feature_matrix(descriptors_list, limit=300):\n","    features = []\n","    for descriptor in descriptors_list:\n","      temp = descriptor.flatten()\n","      if (len(temp) < 12800):\n","        pad_size = 12800 - len(temp)\n","        temp = np.pad(temp, (0,pad_size), 'constant')\n","        print(len(temp))\n","      features.append(temp)\n","    return features"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"OfcCWhukgHq3"},"source":["<font size=20>Building model pipeline</font>"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":406,"status":"ok","timestamp":1684569987649,"user":{"displayName":"Bishoy Tadros","userId":"03823867321940186287"},"user_tz":-180},"id":"46-7mTBBgHq4"},"outputs":[],"source":["def model_pipeline(X_train, Y_train, X_valid, Y_valid, model):\n","\n","    model.fit(X_train, Y_train)\n","    train_acc = model.score(X_train, Y_train)\n","\n","    predictions = model.predict(X_valid)\n","\n","    val_acc = sklearn.metrics.accuracy_score(Y_valid, predictions)\n","    cm = confusion_matrix(Y_valid, predictions)\n","    disp = ConfusionMatrixDisplay(\n","        confusion_matrix=cm)\n","    report = sklearn.metrics.classification_report(Y_valid, predictions)\n","\n","    disp.plot()\n","    plt.show()\n","\n","    weighted_f1 = f1_score(Y_valid, predictions, average='weighted')\n","\n","    return model, report, train_acc, val_acc, weighted_f1\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"WTBSPG1EgHq5"},"source":["<font size=20>Grid Search for hyperparameter tuning</font>"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":344,"status":"ok","timestamp":1684569990490,"user":{"displayName":"Bishoy Tadros","userId":"03823867321940186287"},"user_tz":-180},"id":"B-GCx_4bgHq6"},"outputs":[],"source":["def grid_search(X_train, Y_train, X_validation, Y_validation, algorithm='gbtree'):\n","    param_grid = {\n","        'n_estimators': [5, 50, 100, 200],\n","        'eta': [1, 0.1, 0.01, 0.001],\n","        'booster': [algorithm],\n","    }\n","\n","    grid = GridSearchCV(XGBClassifier(), param_grid, refit=True, verbose=0)\n","    model, report, train_acc, val_acc, weighted_f1 = model_pipeline(\n","        X_train, Y_train, X_validation, Y_validation, grid)\n","\n","    scores = grid.cv_results_['mean_test_score'].reshape(\n","        len(param_grid['n_estimators']), len(param_grid['eta']))\n","\n","    plt.imshow(scores, interpolation='nearest', cmap=plt.cm.hot)\n","    plt.xlabel('eta')\n","    plt.ylabel('n_estimators')\n","    plt.colorbar()\n","    plt.xticks(np.arange(\n","        len(param_grid['eta'])), param_grid['eta'], rotation=45)\n","    plt.yticks(\n","        np.arange(len(param_grid['n_estimators'])), param_grid['n_estimators'])\n","    plt.title('Validation accuracy')\n","    plt.show()\n","\n","    print(grid.best_params_)\n","    return model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":95572,"status":"ok","timestamp":1684570092011,"user":{"displayName":"Bishoy Tadros","userId":"03823867321940186287"},"user_tz":-180},"id":"P7H3NCAIgHq7"},"outputs":[],"source":["# preprocess the images\n","images = process_images(\n","    '/content/drive/MyDrive/Satellite_Imagery/dataset/train/flooded')\n","images += process_images(\n","    '/content/drive/MyDrive/Satellite_Imagery/dataset/train/non-flooded')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9795,"status":"ok","timestamp":1684570267581,"user":{"displayName":"Bishoy Tadros","userId":"03823867321940186287"},"user_tz":-180},"id":"7VLSCVRdgHq9"},"outputs":[],"source":["# extract LBP features\n","LBP_features = extract_LBP_features(images)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":349,"status":"ok","timestamp":1684570297553,"user":{"displayName":"Bishoy Tadros","userId":"03823867321940186287"},"user_tz":-180},"id":"h_unXyyAgsCc"},"outputs":[],"source":["# split the data into train and validation\n","from sklearn.model_selection import train_test_split\n","\n","flooded: int = 1\n","non_flooded: int = 0\n","X_train, X_test, y_train, y_test = train_test_split(\n","    LBP_features, [flooded] * 365 + [non_flooded] * 365, test_size=0.2)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":484},"executionInfo":{"elapsed":853,"status":"ok","timestamp":1684570302353,"user":{"displayName":"Bishoy Tadros","userId":"03823867321940186287"},"user_tz":-180},"id":"6OM-jsyYh12c","outputId":"38527f67-51d3-469a-c8c2-de3ac9c1d30a"},"outputs":[],"source":["model = XGBClassifier()\n","model, report, train_acc, val_acc, weighted_f1 = model_pipeline(X_train, y_train, X_test, y_test, model)\n","print(val_acc)\n","print(weighted_f1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"executionInfo":{"elapsed":1441091,"status":"error","timestamp":1684527156310,"user":{"displayName":"Bishoy Tadros","userId":"03823867321940186287"},"user_tz":-180},"id":"OrB5WCdZiiuy","outputId":"c54636c1-ea05-41e3-b950-4f0c943d0649"},"outputs":[],"source":["boosters = {booster: None for booster in ['gbtree', 'gblinear']}\n","for booster in boosters:\n","    boosters[booster] = grid_search(\n","        X_train, y_train, X_test, y_test, booster)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
